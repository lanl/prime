{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write as a train loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n",
      "Loss: 0.8311 | Accuracy: 7.78%\n",
      "CPU times: user 69 ms, sys: 5.66 ms, total: 74.7 ms\n",
      "Wall time: 332 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expected_aa-&gt;predicted_aa</th>\n",
       "      <th>epoch 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S-&gt;S</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F-&gt;G</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-&gt;G</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V-&gt;L</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V-&gt;S</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>C-&gt;N</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>V-&gt;T</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Q-&gt;L</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>H-&gt;D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>A-&gt;L</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   expected_aa->predicted_aa  epoch 1\n",
       "0                       S->S        6\n",
       "1                       F->G        6\n",
       "2                       A->G        6\n",
       "3                       V->L        5\n",
       "4                       V->S        5\n",
       "..                       ...      ...\n",
       "80                      C->N        1\n",
       "81                      V->T        1\n",
       "82                      Q->L        1\n",
       "83                      H->D        1\n",
       "84                      A->L        1\n",
       "\n",
       "[85 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from transformers import EsmTokenizer, EsmForMaskedLM, AdamW\n",
    "\n",
    "# Training configuration\n",
    "num_epochs = 1\n",
    "lr = 5e-5\n",
    "max_len = 280\n",
    "mask_prob = 0.15\n",
    "\n",
    "# Initialize model and tokenizer\n",
    "model_name = \"facebook/esm2_t6_8M_UR50D\"\n",
    "tokenizer = EsmTokenizer.from_pretrained(model_name, cache_dir=\".cache\")\n",
    "model = EsmForMaskedLM.from_pretrained(model_name, cache_dir=\".cache\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Sample protein sequences (same as before)\n",
    "sequences = [\n",
    "    \"RVQPTESIVRFPNITNLCPFGEVFNATRFSSVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYRYRLFRKSNLKPFERDISTEIYQAGSKPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNF\",\n",
    "    \"RVQPTESIVRFPNITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNPAPFFTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGNIADYNYKLPDDFTGCVIAWNSNKLDSKVSGNYNYLYRLFRKSNLKPFERDISTEIYQAGNKPCNGVAGFNCYFPLRSYSFRPTYGVGHQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNF\",\n",
    "    \"RVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYRYRLFRKSNLKPFERDISTEIYQAGSKPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNF\",\n",
    "    \"RVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYRYRLFRKSNLKPFERDISTEIYQAGSKPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNF\",\n",
    "    \"RVQPTESIVRFPNITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNLAPFFTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGNIADYNYKLPDDFTGCVIAWNSNKLDSKVSGNYNYLYRLFRKSNLKPFERDISTEIYQAGNKPCNGVAGFNCYFPLRSYSFRPTYGVGHQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNF\",\n",
    "]   \n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=0.01)\n",
    "aa_preds_tracker = {}\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    aa_substitutions = []\n",
    "    \n",
    "    # Tokenize sequences fresh each epoch (simulating different batches)\n",
    "    tokenized_seqs = tokenizer(sequences, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_len)\n",
    "    tokenized_seqs = {k: v.to(device) for k, v in tokenized_seqs.items()}\n",
    "    original_ids = tokenized_seqs[\"input_ids\"]\n",
    "    \n",
    "    # Generate new mask for each epoch\n",
    "    torch.manual_seed(0)\n",
    "    rand = torch.rand(original_ids.shape, device=device)\n",
    "    mask_arr = (rand < mask_prob) * \\\n",
    "               (original_ids != tokenizer.cls_token_id) * \\\n",
    "               (original_ids != tokenizer.eos_token_id) * \\\n",
    "               (original_ids != tokenizer.pad_token_id)\n",
    "    \n",
    "    masked_original_ids = original_ids.clone()\n",
    "    masked_original_ids[mask_arr] = tokenizer.mask_token_id\n",
    "\n",
    "    # Forward pass\n",
    "    model.eval()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(masked_original_ids, labels=original_ids)\n",
    "    loss = outputs.loss\n",
    "    preds = outputs.logits\n",
    "    \n",
    "    # Backward pass and optimize\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    predicted_ids = torch.argmax(preds, dim=-1)\n",
    "    mask = (masked_original_ids == tokenizer.mask_token_id)\n",
    "    \n",
    "    original_tokens = original_ids[mask]\n",
    "    predicted_tokens = predicted_ids[mask]\n",
    "    correct = (original_tokens == predicted_tokens).sum().item()\n",
    "    total = mask.sum().item()\n",
    "    accuracy = (correct / total) * 100 if total > 0 else 0.0\n",
    "\n",
    "    aa_keys = [f\"{tokenizer.convert_ids_to_tokens(o.item())}->{tokenizer.convert_ids_to_tokens(p.item())}\"\n",
    "               for o, p in zip(original_tokens, predicted_tokens)]\n",
    "    aa_substitutions.extend(aa_keys)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Loss: {loss.item():.4f} | Accuracy: {accuracy:.2f}%\")\n",
    "    aa_counter = Counter(aa_substitutions)\n",
    "    aa_preds_tracker[epoch + 1] = aa_counter\n",
    "\n",
    "df = pd.DataFrame.from_dict(aa_preds_tracker, orient='index').T\n",
    "\n",
    "# Rename columns for clarity\n",
    "df.columns = [f'epoch {i}' for i in df.columns]\n",
    "\n",
    "# Reset index and rename the index column\n",
    "df.rename_axis(index='expected_aa->predicted_aa', inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Fill NaN values with 0 and sort by total count\n",
    "df = df.fillna(0)\n",
    "df['total'] = df.iloc[:, 1:].sum(axis=1)\n",
    "df = df.sort_values('total', ascending=False).drop('total', axis=1)\n",
    "\n",
    "# Reset index again\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to test if this is properly filtering out special tokens, when encountered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: ['A', '<pad>', 'C', '<eos>']\n",
      "Predicted: ['A', '<pad>', 'A', '<pad>']\n",
      "Substitutions: ['A->A', '<pad>-><pad>', 'C->A', '<eos>-><pad>']\n",
      "Accuracy: 50.00%\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Only two valid amino acid substitutions should be considered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Assertions\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m total \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly two valid amino acid substitutions should be considered\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m correct \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly A->A is correct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA->A\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m aa_keys\n",
      "\u001b[0;31mAssertionError\u001b[0m: Only two valid amino acid substitutions should be considered"
     ]
    }
   ],
   "source": [
    "from transformers import EsmTokenizer, EsmForMaskedLM\n",
    "import torch\n",
    "\n",
    "# Load model/tokenizer\n",
    "model_name = \"facebook/esm2_t6_8M_UR50D\"\n",
    "tokenizer = EsmTokenizer.from_pretrained(model_name, cache_dir=\".cache\")\n",
    "model = EsmForMaskedLM.from_pretrained(model_name, cache_dir=\".cache\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Get special tokens and a few amino acids\n",
    "pad_id = tokenizer.pad_token_id\n",
    "eos_id = tokenizer.eos_token_id\n",
    "a_id = tokenizer.convert_tokens_to_ids(\"A\")\n",
    "c_id = tokenizer.convert_tokens_to_ids(\"C\")\n",
    "\n",
    "# Simulate model outputs (including special tokens)\n",
    "original_tokens = torch.tensor([a_id, pad_id, c_id, eos_id], device=device)\n",
    "predicted_tokens = torch.tensor([a_id, pad_id, a_id, pad_id], device=device)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct = (original_tokens == predicted_tokens).sum().item()\n",
    "total = original_tokens.numel()\n",
    "accuracy = (correct / total) * 100\n",
    "\n",
    "# Substitution keys (filtered)\n",
    "aa_keys = [\n",
    "    f\"{tokenizer.convert_ids_to_tokens(o.item())}->{tokenizer.convert_ids_to_tokens(p.item())}\"\n",
    "    for o, p in zip(original_tokens, predicted_tokens)\n",
    "]\n",
    "\n",
    "print(\"Original:\", tokenizer.convert_ids_to_tokens(original_tokens.tolist()))\n",
    "print(\"Predicted:\", tokenizer.convert_ids_to_tokens(predicted_tokens.tolist()))\n",
    "print(\"Substitutions:\", aa_keys)\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Assertions\n",
    "assert total == 2, \"Only two valid amino acid substitutions should be considered\"\n",
    "assert correct == 1, \"Only A->A is correct\"\n",
    "assert \"A->A\" in aa_keys\n",
    "assert all(\"<pad>\" not in k and \"<eos>\" not in k for k in aa_keys), \"Special tokens should not be in substitutions\"\n",
    "print(\"âœ… Test passed (no special tokens included).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try filtering the special tokens out to only amino acids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: ['A', 'C']\n",
      "Predicted: ['A', 'A']\n",
      "Substitutions: ['A->A', 'C->A']\n",
      "Accuracy: 50.00%\n",
      "âœ… Test passed (no special tokens included).\n"
     ]
    }
   ],
   "source": [
    "from transformers import EsmTokenizer, EsmForMaskedLM\n",
    "import torch\n",
    "\n",
    "# Load model/tokenizer\n",
    "model_name = \"facebook/esm2_t6_8M_UR50D\"\n",
    "tokenizer = EsmTokenizer.from_pretrained(model_name, cache_dir=\".cache\")\n",
    "model = EsmForMaskedLM.from_pretrained(model_name, cache_dir=\".cache\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Get special tokens and a few amino acids\n",
    "pad_id = tokenizer.pad_token_id\n",
    "eos_id = tokenizer.eos_token_id\n",
    "a_id = tokenizer.convert_tokens_to_ids(\"A\")\n",
    "c_id = tokenizer.convert_tokens_to_ids(\"C\")\n",
    "\n",
    "# Simulate model outputs (including special tokens)\n",
    "original_tokens = torch.tensor([a_id, pad_id, c_id, eos_id], device=device)\n",
    "predicted_tokens = torch.tensor([a_id, pad_id, a_id, pad_id], device=device)\n",
    "\n",
    "# Filter to only canonical amino acids\n",
    "aa_ids_tensor = torch.tensor([tokenizer.convert_tokens_to_ids(aa) for aa in \"ACDEFGHIKLMNPQRSTVWY\"], device=device)\n",
    "is_aa_only = torch.isin(original_tokens, aa_ids_tensor) & torch.isin(predicted_tokens, aa_ids_tensor)\n",
    "aa_only_original = original_tokens[is_aa_only]\n",
    "aa_only_predicted = predicted_tokens[is_aa_only]\n",
    "\n",
    "# Calculate accuracy on amino acids only\n",
    "correct = (aa_only_original == aa_only_predicted).sum().item()\n",
    "total = is_aa_only.sum().item()\n",
    "accuracy = (correct / total) * 100 if total > 0 else 0.0\n",
    "\n",
    "# Substitution keys (filtered)\n",
    "aa_keys = [\n",
    "    f\"{tokenizer.convert_ids_to_tokens(o.item())}->{tokenizer.convert_ids_to_tokens(p.item())}\"\n",
    "    for o, p in zip(aa_only_original, aa_only_predicted)\n",
    "]\n",
    "\n",
    "print(\"Original:\", tokenizer.convert_ids_to_tokens(aa_only_original.tolist()))\n",
    "print(\"Predicted:\", tokenizer.convert_ids_to_tokens(aa_only_predicted.tolist()))\n",
    "print(\"Substitutions:\", aa_keys)\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Assertions\n",
    "assert total == 2, \"Only two valid amino acid substitutions should be considered\"\n",
    "assert correct == 1, \"Only A->A is correct\"\n",
    "assert \"A->A\" in aa_keys\n",
    "assert all(\"<pad>\" not in k and \"<eos>\" not in k for k in aa_keys), \"Special tokens should not be in substitutions\"\n",
    "print(\"âœ… Test passed (no special tokens included).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now fix the train loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n",
      "Loss: 0.8311 | Accuracy: 7.78%\n",
      "CPU times: user 68.6 ms, sys: 6.96 ms, total: 75.5 ms\n",
      "Wall time: 343 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expected_aa-&gt;predicted_aa</th>\n",
       "      <th>epoch 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S-&gt;S</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F-&gt;G</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-&gt;G</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V-&gt;L</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V-&gt;S</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>C-&gt;N</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>V-&gt;T</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Q-&gt;L</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>H-&gt;D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>A-&gt;L</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   expected_aa->predicted_aa  epoch 1\n",
       "0                       S->S        6\n",
       "1                       F->G        6\n",
       "2                       A->G        6\n",
       "3                       V->L        5\n",
       "4                       V->S        5\n",
       "..                       ...      ...\n",
       "80                      C->N        1\n",
       "81                      V->T        1\n",
       "82                      Q->L        1\n",
       "83                      H->D        1\n",
       "84                      A->L        1\n",
       "\n",
       "[85 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from transformers import EsmTokenizer, EsmForMaskedLM, AdamW\n",
    "\n",
    "# Training configuration\n",
    "num_epochs = 1\n",
    "lr = 5e-5\n",
    "max_len = 280\n",
    "mask_prob = 0.15\n",
    "\n",
    "# Initialize model and tokenizer\n",
    "model_name = \"facebook/esm2_t6_8M_UR50D\"\n",
    "tokenizer = EsmTokenizer.from_pretrained(model_name, cache_dir=\".cache\")\n",
    "model = EsmForMaskedLM.from_pretrained(model_name, cache_dir=\".cache\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Sample protein sequences (same as before)\n",
    "sequences = [\n",
    "    \"RVQPTESIVRFPNITNLCPFGEVFNATRFSSVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYRYRLFRKSNLKPFERDISTEIYQAGSKPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNF\",\n",
    "    \"RVQPTESIVRFPNITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNPAPFFTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGNIADYNYKLPDDFTGCVIAWNSNKLDSKVSGNYNYLYRLFRKSNLKPFERDISTEIYQAGNKPCNGVAGFNCYFPLRSYSFRPTYGVGHQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNF\",\n",
    "    \"RVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYRYRLFRKSNLKPFERDISTEIYQAGSKPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNF\",\n",
    "    \"RVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYRYRLFRKSNLKPFERDISTEIYQAGSKPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNF\",\n",
    "    \"RVQPTESIVRFPNITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNLAPFFTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGNIADYNYKLPDDFTGCVIAWNSNKLDSKVSGNYNYLYRLFRKSNLKPFERDISTEIYQAGNKPCNGVAGFNCYFPLRSYSFRPTYGVGHQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNF\",\n",
    "]   \n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=0.01)\n",
    "aa_preds_tracker = {}\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    aa_substitutions = []\n",
    "    \n",
    "    # Tokenize sequences fresh each epoch (simulating different batches)\n",
    "    tokenized_seqs = tokenizer(sequences, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_len)\n",
    "    tokenized_seqs = {k: v.to(device) for k, v in tokenized_seqs.items()}\n",
    "    original_ids = tokenized_seqs[\"input_ids\"]\n",
    "    attention_mask = tokenized_seqs[\"attention_mask\"]\n",
    "    \n",
    "    # Generate new mask for each epoch\n",
    "    torch.manual_seed(0)\n",
    "    rand = torch.rand(original_ids.shape, device=device)\n",
    "    mask_arr = (rand < mask_prob) * \\\n",
    "               (original_ids != tokenizer.cls_token_id) * \\\n",
    "               (original_ids != tokenizer.eos_token_id) * \\\n",
    "               (original_ids != tokenizer.pad_token_id)\n",
    "    \n",
    "    masked_original_ids = original_ids.clone()\n",
    "    masked_original_ids[mask_arr] = tokenizer.mask_token_id\n",
    "\n",
    "    # Forward pass\n",
    "    model.eval()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_ids=masked_original_ids, attention_mask=attention_mask, labels=original_ids)\n",
    "    loss = outputs.loss\n",
    "    preds = outputs.logits\n",
    "    \n",
    "    # Backward pass and optimize\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    predicted_ids = torch.argmax(preds, dim=-1)\n",
    "    mask = (masked_original_ids == tokenizer.mask_token_id)\n",
    "    \n",
    "    original_tokens = original_ids[mask]\n",
    "    predicted_tokens = predicted_ids[mask]\n",
    "\n",
    "    aa_ids_tensor = torch.tensor([tokenizer.convert_tokens_to_ids(aa) for aa in \"ACDEFGHIKLMNPQRSTVWY\"], device=device)\n",
    "    is_aa_only = torch.isin(original_tokens, aa_ids_tensor) & torch.isin(predicted_tokens, aa_ids_tensor)\n",
    "    aa_only_original = original_tokens[is_aa_only]\n",
    "    aa_only_predicted = predicted_tokens[is_aa_only]\n",
    "\n",
    "    # Calculate accuracy \n",
    "    correct = (aa_only_original == aa_only_predicted).sum().item()\n",
    "    total = is_aa_only.sum().item()\n",
    "    accuracy = (correct / total) * 100 if total > 0 else 0.0\n",
    "\n",
    "    aa_keys = [f\"{tokenizer.convert_ids_to_tokens(o.item())}->{tokenizer.convert_ids_to_tokens(p.item())}\"\n",
    "               for o, p in zip(original_tokens, predicted_tokens)]\n",
    "    aa_substitutions.extend(aa_keys)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Loss: {loss.item():.4f} | Accuracy: {accuracy:.2f}%\")\n",
    "    aa_counter = Counter(aa_substitutions)\n",
    "\n",
    "    # for substitution, count in aa_counter.items():\n",
    "    #     substitution = substitution.split(\"->\")\n",
    "    #     original = substitution[0]\n",
    "    #     predicted = substitution[1]\n",
    "        \n",
    "    #     print(f\"{original}->{predicted}: {count}\")\n",
    "\n",
    "    aa_preds_tracker[epoch + 1] = aa_counter\n",
    "\n",
    "df = pd.DataFrame.from_dict(aa_preds_tracker, orient='index').T\n",
    "\n",
    "# Rename columns for clarity\n",
    "df.columns = [f'epoch {i}' for i in df.columns]\n",
    "\n",
    "# Reset index and rename the index column\n",
    "df.rename_axis(index='expected_aa->predicted_aa', inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Fill NaN values with 0 and sort by total count\n",
    "df = df.fillna(0)\n",
    "df['total'] = df.iloc[:, 1:].sum(axis=1)\n",
    "df = df.sort_values('total', ascending=False).drop('total', axis=1)\n",
    "\n",
    "# Reset index again\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
